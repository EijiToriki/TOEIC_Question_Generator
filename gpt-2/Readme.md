## 概要
- システムの文章生成器を担っている GPT2 に関わるディレクトリ
- Question_Generater に文章生成器と問題生成器がセットになったプログラムがあるため，ここのプログラムをシステムに使うことはない
- GPT2でまず文章を作ってみたいという際に動かすのをおすすめする

## ここに入れるプログラム/データ
- gpt-2を自分用にカスタマイズしたプログラム
- gpt-2を使用する際のデータ

## プログラム
- interactive_conditional_samples.py
  - オリジナル：文の入力を要求され，ある文を入力すると，その文の続きとなるストーリーを2パターン出力する．文の入力要求は無限に続く．
  - カスタマイズ後：入力ファイルの文を1文1文取り出し，その文に対するストーリーを生成する．生成したストーリーはリストに格納し，後にファイルに出力する．出力ファイル名は，"gene_sen.txt"である．
  - 実行方法：(ex)!python3 src/interactive_conditional_samples.py --model_name='774M' --nsamples=2 --top_k=40 --temperature=.80
    - model_name : 117M , 345M , 774M , 1558M から選ぶ．大きいサイズになればなるほど性能up．
    - nsamples：出力したいサンプル数．
    - top_k：多様性をコントロールする整数値，とりあえず40を設定しておけばOK．
    - temperture：0～1の小数値，高い値程よりランダムな値になる．
    - length：サンプルで出力したいトークン(単語)の数．
    
## データ
- mini_toeic_data.txt
  - TOEIC問題集から引っ張ってきた5文のみのデータ．
  - お試し実行用．
- gene_sen.txt
  - interactive_conditional_samples.py が正常に実行されると生成される．
  - 入力ファイルに対するストーリーを書き込んだファイル．
  - ここに示しているファイルは mini_toeic_data.txt に対するストーリーを書き込んでいる．
  - このファイルに何らかの処理をして，問題文にしたい．
    - 短すぎる文をカット．
    - 改行とかのフォーマットを整える．
  
